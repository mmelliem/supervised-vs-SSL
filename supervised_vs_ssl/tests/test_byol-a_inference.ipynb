{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a60985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available: True\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA GeForce GTX 1060 3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melan/miniconda3/envs/byola/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1060 3GB which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home/melan/miniconda3/envs/byola/lib/python3.10/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home/melan/miniconda3/envs/byola/lib/python3.10/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1060 3GB with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1060 3GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Is GPU available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing librosa if it makes a cochleagram\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y, sr = librosa.load(\"test.wav\", sr=None)\n",
    "# simple cochleagram approximation using STFT magnitude\n",
    "S = np.abs(librosa.stft(y, n_fft=512, hop_length=256))\n",
    "plt.imshow(20*np.log10(S+1e-6), origin='lower', aspect='auto')\n",
    "plt.title(\"Cochleagram-like representation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fe9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melan/supervised-vs-SSL/supervised_vs_ssl/tests/../models/byol-a/v2/byol_a2/common.py:31: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "/home/melan/miniconda3/envs/byola/lib/python3.10/site-packages/torchaudio/_internal/module_utils.py:71: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[43mload_yaml_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig_v2.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use your config file path\u001b[39;00m\n\u001b[1;32m     14\u001b[0m stats \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9.660292\u001b[39m, \u001b[38;5;241m4.7219563\u001b[39m]\n\u001b[1;32m     15\u001b[0m to_melspec \u001b[38;5;241m=\u001b[39m nnAudio\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mMelSpectrogram(\n\u001b[1;32m     16\u001b[0m     sr\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39msample_rate,\n\u001b[1;32m     17\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_fft,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/supervised-vs-SSL/supervised_vs_ssl/tests/../models/byol-a/v2/byol_a2/common.py:51\u001b[0m, in \u001b[0;36mload_yaml_config\u001b[0;34m(path_to_config)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads yaml configuration settings as an EasyDict object.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m path_to_config \u001b[38;5;241m=\u001b[39m Path(path_to_config)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m path_to_config\u001b[38;5;241m.\u001b[39mis_file()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_to_config) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     53\u001b[0m     yaml_contents \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../models/byol-a/v2')\n",
    "\n",
    "from byol_a2.common import load_yaml_config\n",
    "from byol_a2.augmentations import PrecomputedNorm\n",
    "from byol_a2.models import AudioNTT2022, load_pretrained_weights\n",
    "import nnAudio.features\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cfg = load_yaml_config('config_v2.yaml')  # Use your config file path\n",
    "\n",
    "stats = [-9.660292, 4.7219563]\n",
    "to_melspec = nnAudio.features.MelSpectrogram(\n",
    "    sr=cfg.sample_rate,\n",
    "    n_fft=cfg.n_fft,\n",
    "    win_length=cfg.win_length,\n",
    "    hop_length=cfg.hop_length,\n",
    "    n_mels=cfg.n_mels,\n",
    "    fmin=cfg.f_min,\n",
    "    fmax=cfg.f_max,\n",
    "    center=True,\n",
    "    power=2,\n",
    "    verbose=False,\n",
    ")\n",
    "normalizer = PrecomputedNorm(stats)\n",
    "\n",
    "model = AudioNTT2022(n_mels=cfg.n_mels, d=cfg.feature_d)\n",
    "load_pretrained_weights(model, 'AudioNTT2022-BYOLA-64x96d3072.pth')\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "wav_dir = '/path/to/your/wav/files'  # Change to your .wav directory\n",
    "wav_files = [f for f in os.listdir(wav_dir) if f.endswith('.wav')]\n",
    "\n",
    "for f in wav_files[:5]:  # Run on first 5 files\n",
    "    wav, sr = torchaudio.load(os.path.join(wav_dir, f))\n",
    "    assert sr == cfg.sample_rate, \"Sample rate mismatch!\"\n",
    "    wav = wav[:, :int(cfg.unit_sec * cfg.sample_rate)]  # Crop to 0.95s if needed\n",
    "    lms = normalizer((to_melspec(wav) + torch.finfo(torch.float).eps).log())\n",
    "    lms = lms[:, :96]  # Crop/pad to 96 frames\n",
    "    if lms.shape[1] < 96:\n",
    "        pad_width = 96 - lms.shape[1]\n",
    "        lms = torch.nn.functional.pad(lms, (0, pad_width))\n",
    "    with torch.no_grad():\n",
    "        features = model(lms.unsqueeze(0).to(device))\n",
    "    print(f\"File: {f}, Feature shape: {features.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
